# Day 46: Event-Driven Processing with Amazon S3 and Lambda

The DevOps team is working on automating file management between two S3 buckets. The task is to create a public S3 bucket for file uploads and a private S3 bucket for securely storing the files. A Lambda function will be triggered automatically whenever a file is uploaded to the public S3 bucket, which will copy the file to the private bucket. Additionally, logs of the operation will be stored in a DynamoDB table. The logs should include details such as the source bucket, destination bucket, and the object key of the file that was copied. This will help the team maintain better security and visibility for file transfers.

- **Create a public S3 bucket** named `nautilus-public-1663`. Ensure that the bucket allows public access to its objects.
  
- **Create a private S3 bucket** named `nautilus-private-11344`. Ensure that the bucket does not allow public access.
  
- **Create a Lambda function** named `nautilus-copyfunction`. This function should be triggered by uploads to the public S3 bucket and should copy the uploaded file to the private bucket. Create the necessary policies and a role named `lambda_execution_role`. Attach these policies to the role, and then link this role to the Lambda function.

- `lambda-function.py` is already present under the `/root/` directory on AWS client host, replace `REPLACE-WITH-YOUR-DYNAMODB-TABLE` and `REPLACE-WITH-YOUR-PRIVATE-BUCKET` values.

- **Create a DynamoDB table** named `nautilus-S3CopyLogs` with a partition key `LogID` (string). This table will store logs generated by the Lambda function, including details such as source bucket name, destination bucket name, and object key.

- For testing upload the file `sample.zip` located in the `/root` directory on the client host to the public S3 bucket. The Lambda function should trigger and copy the file to the private bucket.

- **Verify that the file** has been successfully copied to the private bucket by checking the private bucket in the S3 console.

- **Verify that a log entry has been created** in the DynamoDB table containing the file copy details.

## Task 1: Create a public S3 bucket

1. **Go to S3 Bucket and click `Create a bucket`.**

   <img width="310" height="232" alt="image" src="https://github.com/user-attachments/assets/fd1e718d-05a8-4b6e-a941-ab421b8fa59e" />

2. **Under `General configuration` section, enter name and select `Bucket type` as `General purpose`.**

   <img width="1299" height="433" alt="image" src="https://github.com/user-attachments/assets/a35c8e35-c65e-470c-a120-2c0d3be95983" />

3. **Set `Object Ownership` to `ACL enabled`.**

   <img width="1299" height="403" alt="image" src="https://github.com/user-attachments/assets/75106318-ee9f-4a0d-b6ec-b03312f1543b" />

4. **To make the bucket public check Block all public access and Acknowledge the warning.**

   <img width="1303" height="449" alt="image" src="https://github.com/user-attachments/assets/1d80c4e5-1905-489d-b9c8-689399489704" />

5. **Create the public s3 bucket.**

   <img width="908" height="278" alt="image" src="https://github.com/user-attachments/assets/5b043d0e-e851-42d4-b96f-a2d2f0afe9c7" />

6. **Open `nautilus-public-1663`. Go to `Permissions` > `Bucket policy`.**
   
   <img width="1345" height="110" alt="image" src="https://github.com/user-attachments/assets/352b9893-b0a9-41ab-a190-31a3e130c412" />

  **Add this policy:**

   ```yaml
   {
    "Version": "2012-10-17",
    "Statement": [
      {
        "Sid": "PublicReadGetObject",
        "Effect": "Allow",
        "Principal": "*",
        "Action": "s3:GetObject",
        "Resource": "arn:aws:s3:::nautilus-public-1663/*"
      }
    ]
    }
   ```

   <img width="1303" height="376" alt="image" src="https://github.com/user-attachments/assets/3eb898af-7c00-4725-a465-f5ee6a81e836" />


## Task 1: Create a private S3 bucket

1. **Go to S3 Bucket and click `Create a bucket`.**

   <img width="310" height="232" alt="image" src="https://github.com/user-attachments/assets/fd1e718d-05a8-4b6e-a941-ab421b8fa59e" />

2. **Under `General configuration` section, enter name and select `Bucket type` as `General purpose`.**

   <img width="1303" height="375" alt="image" src="https://github.com/user-attachments/assets/5c08a966-1f61-41b6-ac96-39c503f3cf89" />

3. **Keep Block all public access `ENABLED`.**
   
   <img width="1303" height="337" alt="image" src="https://github.com/user-attachments/assets/0364633f-e1ba-4d7f-a21e-f36a62551e84" />

5. **Create the private S3 bucket.**

   <img width="910" height="299" alt="image" src="https://github.com/user-attachments/assets/7f90bae4-d3ed-4bab-8219-fcfc607f0062" />

## Task 3: Create DynamoDB Table for Logs

1. **Go to `DynamoDB` > `Create table`.**

   <img width="340" height="170" alt="image" src="https://github.com/user-attachments/assets/fe82dc97-88b1-4247-b231-9b4bf4c61939" />

2. **Table name: `nautilus-S3CopyLogs`**.
   
    - Partition key: `LogID`
    - Type: `String`
    - **Leave all other settings as default**

   <img width="1303" height="382" alt="image" src="https://github.com/user-attachments/assets/1f16419e-8c45-480e-aaee-2b16530fcff4" />

4. **Create DynamoDB table.**

   <img width="1088" height="187" alt="image" src="https://github.com/user-attachments/assets/6a3ebd79-965c-4d0c-93ed-3ec4cb3f0c46" />


## Task 4: Create IAM Role for Lambda

1. **Go to `IAM` > `Roles` > `Create role`.**.
   
   - **Trusted entity**: **AWS service**

     <img width="1049" height="253" alt="image" src="https://github.com/user-attachments/assets/124cb53b-9147-4069-81f5-69cfe1f92495" />

   -  **Use case**: **Lambda**

      <img width="1049" height="265" alt="image" src="https://github.com/user-attachments/assets/80981664-6a0f-4fb0-b663-650f76f03a30" />

3. **Attach following policies to the role:**

   `AmazonS3FullAccess`

   `AmazonDynamoDBFullAccess`

   `AWSLambdaBasicExecutionRole`

   <img width="1049" height="193" alt="image" src="https://github.com/user-attachments/assets/d98881d0-d862-4a6a-9934-42115e1a3499" />

4. **Set role name.**

   <img width="1049" height="280" alt="image" src="https://github.com/user-attachments/assets/cf9f394a-076a-460f-9f24-3c84b29a7eb2" />

5. **Create the IAM role.**

   <img width="1079" height="179" alt="image" src="https://github.com/user-attachments/assets/767ebf1f-cc37-4847-878e-6fffb0d5f470" />


## Task 5: Prepare Lambda Function Code

1. **On the AWS client host, edit the existing file:**
    ```sh
    vi /root/lambda-function.py
    ```
    
    **Replace:**

    `REPLACE-WITH-YOUR-DYNAMODB-TABLE` → `nautilus-S3CopyLogs`
   
    `REPLACE-WITH-YOUR-PRIVATE-BUCKET` → `nautilus-private-11344`


## Task 6: Create the Lambda Function

1. **Go to `Lambda` > `Create function`.**

   <img width="317" height="180" alt="image" src="https://github.com/user-attachments/assets/a27d4e44-ea0f-41eb-9a7a-e9ada971d53e" />

2. **Choose Author from scratch.**

   <img width="1348" height="156" alt="image" src="https://github.com/user-attachments/assets/c5cf9bba-df21-4123-b1f8-75fefd624162" />

3. **Enter function name: `nautilus-copyfunction` and choose runtime: `Python 3.10`.**

   <img width="1303" height="389" alt="image" src="https://github.com/user-attachments/assets/9070da32-3bd2-4afc-9785-0bd5f2c19581" />

4. **Change default execution role with existing `lambda_execution_role`.**

   <img width="1303" height="261" alt="image" src="https://github.com/user-attachments/assets/af376d5f-1154-4027-bd93-bf8c20835149" />

5. **Create the lambda function.**
   
   <img width="1335" height="381" alt="image" src="https://github.com/user-attachments/assets/b9602373-3465-4f69-9ff6-11f9971b8f5f" />


## Task 7: Upload Function Code

2. **Zip the file first on aws-client host:**

   ```sh
   cd /root
   zip lambda-function.zip lambda-function.py
   ```

3. **Upload Lambda ZIP Using AWS CLI from aws-client host.**

   ```sh
    aws lambda update-function-code \
      --function-name nautilus-copyfunction \
      --zip-file fileb:///root/lambda-function.zip
   ```

4. **Verify update succeeded.**

    ```sh
    aws lambda get-function \
      --function-name nautilus-copyfunction
    ```

5. **Set the Handler inside `nautilus-copyfunction` go to `Runtime settings` click `Edit`.**

   <img width="1303" height="147" alt="image" src="https://github.com/user-attachments/assets/98c514ab-1154-4007-93de-baf6a2c41e09" />

   <img width="1278" height="422" alt="image" src="https://github.com/user-attachments/assets/c06d1ecf-f24b-471d-ad16-5c1575aa5c0e" />


6. **Configure S3 Trigger by from `Configuration` > `Triggers` > `Add trigger`.**

  - **Add trigger:**

    <img width="1333" height="359" alt="image" src="https://github.com/user-attachments/assets/50033969-25e4-4e08-949f-330853c1e6e7" />
    
   - **Select** `S3`
   - **Bucket**: `nautilus-public-1663`
   - **Event type**: `All object create events`

     <img width="1299" height="379" alt="image" src="https://github.com/user-attachments/assets/85d51633-7d85-4800-8090-9efc329ffc1c" />

   - **Acknowledge recursive warning:**

     <img width="1299" height="171" alt="image" src="https://github.com/user-attachments/assets/1c3e9813-7c17-4926-8bf5-021286d2b4b2" />



  - **After adding trigger:**

    <img width="1299" height="352" alt="image" src="https://github.com/user-attachments/assets/0910a025-f485-499d-b82a-30c1f5f45f20" />


## Task 8: Test and verify the Setup

1. **Upload test file from client host.**

   ```sh
   aws s3 cp /root/sample.zip s3://nautilus-public-1663/
   ```

2. **Verify file copy from `S3` > `nautilus-private-11344`. Confirm `sample.zip` exists**

   <img width="1052" height="439" alt="image" src="https://github.com/user-attachments/assets/1574956f-19e0-41ca-b4a4-71e7bff3180c" />



2. **Verify DynamoDB Logs `DynamoDB` > `nautilus-S3CopyLogs`. Go to `Explore table items`.**

   <img width="263" height="369" alt="image" src="https://github.com/user-attachments/assets/8ad912a8-e8e3-42df-878d-1e512c5d01b9" />

3. **You should see an entry containing:**

   - **Source bucket**: `nautilus-public-1663`
   - **Destination bucket**: `nautilus-private-11344`
   - **Object key**: `sample.zip`

     <img width="830" height="155" alt="image" src="https://github.com/user-attachments/assets/732de006-aa06-48b8-870a-589d29909a05" />
